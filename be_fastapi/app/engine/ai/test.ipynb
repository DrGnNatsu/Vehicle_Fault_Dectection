{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc79dec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from ultralytics import YOLO\n",
    "from shapely.geometry import Point, Polygon\n",
    "from collections import defaultdict\n",
    "from sqlalchemy.orm import Session\n",
    "from be_fastapi.app.database.session import SessionLocal\n",
    "from be_fastapi.app.models.zone import Zone \n",
    "\n",
    "class VideoProcessor:\n",
    "    def __init__(self, model_path='be_fastapi\\\\app\\\\engine\\\\ckpt\\\\best.onnx', source_id=None):\n",
    "        \"\"\"\n",
    "        model_path: checkpoint (.pt or .onnx)\n",
    "        source_id: source ID\n",
    "        \"\"\"\n",
    "        self.source_id = source_id\n",
    "        if model_path.endswith('.onnx'):\n",
    "            self.device = 'cpu'\n",
    "            print(f\"[Source {self.source_id}] Running ONNX mode on CPU\")\n",
    "        else:\n",
    "            self.device = 0 if torch.cuda.is_available() else 'cpu'\n",
    "            print(f\"[Source {self.source_id}] Using device: {torch.cuda.get_device_name(0) if self.device == 0 else 'CPU'}\")\n",
    "\n",
    "        self.model = YOLO(model_path, task='detect')\n",
    "\n",
    "        self.CLASS_NAMES = {\n",
    "            0: 'Car', 1: 'Bus', 2: 'Truck', 3: 'Motorcycle',\n",
    "            4: 'Person', 5: 'Traffic Light', \n",
    "            6: 'Helmet', 7: 'No Helmet', 8: 'License Plate'\n",
    "        }\n",
    "        \n",
    "        self.VEHICLE_CLASSES = [0, 1, 2, 3] \n",
    "        self.ATTRIBUTE_CLASSES = [6, 7, 8]\n",
    "        \n",
    "        # load zones from DB\n",
    "        self.zones = {} \n",
    "        if self.source_id:\n",
    "            self.load_zones_from_db(self.source_id)\n",
    "        else:\n",
    "            print(\"No source_id provided, cannot load zones.\")\n",
    "        \n",
    "        # Temporary memory\n",
    "        self.track_history = defaultdict(lambda: [])\n",
    "        self.zone_entry_times = defaultdict(lambda: {})\n",
    "\n",
    "    def load_zones_from_db(self, source_id):\n",
    "        \"\"\"\n",
    "        Load zones from the database for the given source_id.\n",
    "        \"\"\"\n",
    "        db: Session = SessionLocal()\n",
    "        try:\n",
    "            db_zones = db.query(Zone).filter(Zone.source_id == source_id).all()\n",
    "            \n",
    "            self.zones = {}\n",
    "            for z in db_zones:\n",
    "                try:\n",
    "                    points = z.coordinates\n",
    "                    if isinstance(points, str):\n",
    "                        points = json.loads(points) #convert to list if stored as string\n",
    "                    if points and isinstance(points, list) and len(points) >= 3:\n",
    "                        poly = Polygon(points)\n",
    "                        self.zones[z.name] = poly\n",
    "                    else:\n",
    "                        print(f\"Zone '{z.name}' has invalid coordinates.\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error parsing zone '{z.name}': {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error connecting to Database when loading zones: {e}\")\n",
    "        finally:\n",
    "            db.close()\n",
    "\n",
    "    def calculate_iou(self, box1, box2):\n",
    "        \"\"\"\n",
    "            Calculate Intersection over Union (IoU) of two bounding boxes.\n",
    "            box1, box2: [x_min, y_min, x_max, y_max]\n",
    "        \"\"\"\n",
    "        x1 = max(box1[0], box2[0])\n",
    "        y1 = max(box1[1], box2[1])\n",
    "        x2 = min(box1[2], box2[2])\n",
    "        y2 = min(box1[3], box2[3])\n",
    "        \n",
    "        intersection = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "        area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "        area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "        \n",
    "        if area1 + area2 - intersection == 0: return 0\n",
    "        return intersection / (area1 + area2 - intersection)\n",
    "\n",
    "    def estimate_speed(self, track_id, current_center):\n",
    "        \"\"\"\n",
    "            Estimate speed in km/h based on pixel movement.\n",
    "            track_id: ID of the tracked object\n",
    "            sclae_factor: conversion factor from pixels to meters, in this case 0.05 m/pixel\n",
    "        \"\"\"\n",
    "        scale_factor = 0.05\n",
    "        if track_id not in self.track_history or len(self.track_history[track_id]) < 2:\n",
    "            return 0.0\n",
    "        prev_center = self.track_history[track_id][-1]\n",
    "        pixel_dist = np.sqrt((current_center[0] - prev_center[0])**2 + (current_center[1] - prev_center[1])**2)\n",
    "        speed_mps = pixel_dist * scale_factor * 30 \n",
    "        return round(speed_mps * 3.6, 1)\n",
    "\n",
    "    def process_video(self, video_source=0):\n",
    "        cap = cv2.VideoCapture(video_source)\n",
    "        \n",
    "        while cap.isOpened():\n",
    "            success, frame = cap.read()\n",
    "            if not success: break\n",
    "\n",
    "            # Run detection and tracking\n",
    "            results = self.model.track(\n",
    "                frame, \n",
    "                persist=True, \n",
    "                tracker=\"bytetrack.yaml\", \n",
    "                device=self.device,\n",
    "                verbose=False,\n",
    "                conf=0.25\n",
    "            )\n",
    "            \n",
    "            # If no detections, just show original frame\n",
    "            if not results or not results[0].boxes:\n",
    "                cv2.imshow(f\"Cam {self.source_id}\", frame)\n",
    "                if cv2.waitKey(1) & 0xFF == ord(\"q\"): break\n",
    "                continue\n",
    "\n",
    "            # Process results\n",
    "            boxes = results[0].boxes\n",
    "            current_timestamp = datetime.utcnow().isoformat() + \"Z\" # ISO 8601 format\n",
    "            \n",
    "            # Classify boxes into vehicles and attributes\n",
    "            vehicles = []\n",
    "            attributes = []\n",
    "            for box in boxes:\n",
    "                cls_id = int(box.cls[0])\n",
    "                if cls_id in self.VEHICLE_CLASSES:\n",
    "                    vehicles.append(box)\n",
    "                elif cls_id in self.ATTRIBUTE_CLASSES:\n",
    "                    attributes.append(box)\n",
    "\n",
    "            # Process each vehicle\n",
    "            dsl_objects = []\n",
    "            for veh in vehicles:\n",
    "                if veh.id is None: continue \n",
    "                \n",
    "                track_id = int(veh.id[0])\n",
    "                cls_id = int(veh.cls[0])\n",
    "                x1, y1, x2, y2 = veh.xyxy[0].tolist()\n",
    "                center_point = Point((x1 + x2) / 2, (y1 + y2) / 2)\n",
    "                center_tuple = ((x1 + x2) / 2, (y1 + y2) / 2)\n",
    "\n",
    "                self.track_history[track_id].append(center_tuple)\n",
    "                if len(self.track_history[track_id]) > 30:\n",
    "                    self.track_history[track_id].pop(0)\n",
    "\n",
    "                # Gh√©p thu·ªôc t√≠nh\n",
    "                has_helmet = None\n",
    "                license_text = \"Unknown\"\n",
    "                veh_box = [x1, y1, x2, y2]\n",
    "                \n",
    "                for attr in attributes:\n",
    "                    attr_box = attr.xyxy[0].tolist()\n",
    "                    attr_id = int(attr.cls[0])\n",
    "                    if self.calculate_iou(veh_box, attr_box) > 0.01:\n",
    "                        if attr_id == 6: has_helmet = True\n",
    "                        elif attr_id == 7: has_helmet = False\n",
    "                        elif attr_id == 8: license_text = \"DETECTED_PLATE\"\n",
    "\n",
    "                current_zone_name = None\n",
    "                zone_durations = {}\n",
    "                for z_name, z_poly in self.zones.items():\n",
    "                    if z_poly.contains(center_point):\n",
    "                        current_zone_name = z_name \n",
    "                        \n",
    "                        if track_id not in self.zone_entry_times: self.zone_entry_times[track_id] = {}\n",
    "                        if z_name not in self.zone_entry_times[track_id]: self.zone_entry_times[track_id][z_name] = datetime.now()\n",
    "                        \n",
    "                        duration = (datetime.now() - self.zone_entry_times[track_id][z_name]).total_seconds()\n",
    "                        zone_durations[z_name] = round(duration, 1)\n",
    "                    else:\n",
    "                        if track_id in self.zone_entry_times and z_name in self.zone_entry_times[track_id]:\n",
    "                            del self.zone_entry_times[track_id][z_name]\n",
    "\n",
    "                obj_data = {\n",
    "                    \"track_id\": track_id,\n",
    "                    \"class_name\": self.CLASS_NAMES[cls_id],\n",
    "                    \"class_id\": cls_id,\n",
    "                    \"bbox\": [int(x1), int(y1), int(x2), int(y2)],\n",
    "                    \"confidence\": float(veh.conf[0]),\n",
    "                    \"speed_kmh\": self.estimate_speed(track_id, center_tuple),\n",
    "                    \"direction_angle\": 0.0,\n",
    "                    \"current_zone\": current_zone_name,\n",
    "                    \"zone_duration_seconds\": zone_durations,\n",
    "                    \"attributes\": {\n",
    "                        \"has_helmet\": has_helmet,\n",
    "                        \"license_plate_text\": license_text\n",
    "                    }\n",
    "                }\n",
    "                dsl_objects.append(obj_data)\n",
    "\n",
    "            final_json = {\n",
    "                \"source_id\": str(self.source_id), # G·ª≠i ID camera ƒëi k√®m\n",
    "                \"frame_timestamp\": current_timestamp,\n",
    "                \"objects\": dsl_objects\n",
    "            }\n",
    "            \n",
    "\n",
    "            annotated_frame = results[0].plot()\n",
    "            # V·∫Ω v√πng l√™n h√¨nh ƒë·ªÉ debug\n",
    "            for z_name, z_poly in self.zones.items():\n",
    "                pts = np.array(z_poly.exterior.coords, np.int32)\n",
    "                pts = pts.reshape((-1, 1, 2))\n",
    "                cv2.polylines(annotated_frame, [pts], True, (0, 255, 255), 2)\n",
    "                cv2.putText(annotated_frame, z_name, (pts[0][0][0], pts[0][0][1]), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 255), 2)\n",
    "\n",
    "            cv2.imshow(f\"Cam {self.source_id}\", annotated_frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\"\n",
    "    H√†m main ƒë·ªÉ test AI Engine ƒë·ªôc l·∫≠p.\n",
    "    Ch·∫°y file n√†y tr·ª±c ti·∫øp ƒë·ªÉ debug v√† ki·ªÉm tra xem model c√≥ ho·∫°t ƒë·ªông ƒë√∫ng kh√¥ng.\n",
    "    \"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"üöÄ Starting AI Engine Test Mode\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # --- C·∫•u h√¨nh ---\n",
    "    TEST_SOURCE_ID = 1  # ID c·ªßa camera trong Database\n",
    "    MODEL_PATH = 'be_fastapi\\\\app\\\\engine\\\\ckpt\\\\best.onnx'  # ƒê∆∞·ªùng d·∫´n model\n",
    "    VIDEO_SOURCE = 'test_video.mp4'  # C√≥ th·ªÉ l√† file video ho·∫∑c 0 cho webcam\n",
    "    \n",
    "    # --- Kh·ªüi t·∫°o Processor ---\n",
    "    try:\n",
    "        processor = VideoProcessor(\n",
    "            model_path=MODEL_PATH,\n",
    "            source_id=TEST_SOURCE_ID\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ Model loaded successfully: {MODEL_PATH}\")\n",
    "        print(f\"‚úÖ Loaded {len(processor.zones)} zones from database for Source ID {TEST_SOURCE_ID}\")\n",
    "        \n",
    "        if len(processor.zones) == 0:\n",
    "            print(\"‚ö†Ô∏è  WARNING: No zones found! Make sure database has zones for this source_id.\")\n",
    "        \n",
    "        print(\"\\nüìπ Starting video processing...\")\n",
    "        print(\"   Press 'q' to quit\\n\")\n",
    "        \n",
    "        # --- Ch·∫°y x·ª≠ l√Ω video ---\n",
    "        processor.process_video(video_source=VIDEO_SOURCE)\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå ERROR: Model file not found at: {MODEL_PATH}\")\n",
    "        print(\"   Please check the path and make sure the model file exists.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ERROR: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    finally:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"üõë AI Engine stopped\")\n",
    "        print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffbe07bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üñ•Ô∏è  Device: GPU - NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "‚úÖ Model loaded: ../../../app/engine/ckpt/best.pt\n",
      "üìπ Video: ../../../../videos/no_helmet.mp4\n",
      "   Frames: 598, FPS: 25.0, Size: 1920x1080\n",
      "\n",
      "üîç Starting detection...\n",
      "============================================================\n",
      "Frame   39/598: {'Helmet': 4, 'No Helmet': 3}\n",
      "Frame   40/598: {'Helmet': 3, 'No Helmet': 3}\n",
      "Frame   41/598: {'Helmet': 4, 'No Helmet': 4}\n",
      "Frame   42/598: {'Helmet': 5, 'No Helmet': 3}\n",
      "Frame   43/598: {'Helmet': 5, 'No Helmet': 2}\n",
      "Frame   44/598: {'Helmet': 4, 'No Helmet': 3}\n",
      "Frame   45/598: {'Helmet': 4, 'No Helmet': 4}\n",
      "Frame   46/598: {'Helmet': 5, 'No Helmet': 4}\n",
      "Frame   47/598: {'Helmet': 4, 'No Helmet': 6}\n",
      "Frame   48/598: {'Helmet': 4, 'No Helmet': 4}\n",
      "Frame   49/598: {'Helmet': 4, 'No Helmet': 5}\n",
      "Frame   50/598: {'Helmet': 2, 'No Helmet': 8}\n",
      "Frame   51/598: {'Helmet': 2, 'No Helmet': 6}\n",
      "Frame   52/598: {'Helmet': 3, 'No Helmet': 7}\n",
      "Frame   53/598: {'Helmet': 5, 'No Helmet': 6}\n",
      "Frame   54/598: {'Helmet': 5, 'No Helmet': 7}\n",
      "Frame   55/598: {'Helmet': 4, 'No Helmet': 5}\n",
      "Frame   56/598: {'Helmet': 3, 'No Helmet': 6}\n",
      "Frame   57/598: {'Helmet': 4, 'No Helmet': 5}\n",
      "Frame   58/598: {'Helmet': 3, 'No Helmet': 6, 'Person': 1}\n",
      "Frame   59/598: {'No Helmet': 5, 'Helmet': 5}\n",
      "Frame   60/598: {'Helmet': 3, 'No Helmet': 5}\n",
      "Frame   61/598: {'Helmet': 3, 'No Helmet': 5, 'Person': 2}\n",
      "Frame   62/598: {'Helmet': 3, 'No Helmet': 4, 'Person': 2}\n",
      "Frame   63/598: {'Helmet': 3, 'No Helmet': 4, 'Person': 3}\n",
      "Frame   64/598: {'Helmet': 3, 'No Helmet': 3, 'Person': 1}\n",
      "Frame   65/598: {'Helmet': 4, 'No Helmet': 4, 'Person': 1}\n",
      "Frame   66/598: {'No Helmet': 4, 'Helmet': 6, 'Person': 1}\n",
      "Frame   67/598: {'Helmet': 4, 'No Helmet': 3}\n",
      "Frame   68/598: {'Person': 2, 'No Helmet': 4, 'Helmet': 4}\n",
      "Frame   69/598: {'Person': 2, 'Helmet': 4, 'No Helmet': 4}\n",
      "Frame   70/598: {'Person': 2, 'Helmet': 5, 'No Helmet': 3}\n",
      "Frame   71/598: {'Helmet': 7, 'No Helmet': 2, 'Person': 3}\n",
      "Frame   72/598: {'Helmet': 5, 'No Helmet': 3, 'Person': 2}\n",
      "Frame   73/598: {'Helmet': 5, 'Person': 2, 'No Helmet': 3}\n",
      "Frame   74/598: {'Helmet': 4, 'No Helmet': 3, 'Person': 1}\n",
      "Frame   75/598: {'Helmet': 4, 'No Helmet': 3, 'Person': 1}\n",
      "Frame   76/598: {'Helmet': 4, 'No Helmet': 3, 'Person': 1}\n",
      "Frame   77/598: {'Helmet': 3, 'No Helmet': 2}\n",
      "Frame   78/598: {'Helmet': 4, 'No Helmet': 3}\n",
      "Frame   79/598: {'Helmet': 4, 'No Helmet': 1}\n",
      "Frame   80/598: {'Helmet': 6, 'No Helmet': 2}\n",
      "Frame   81/598: {'Helmet': 3, 'No Helmet': 2}\n",
      "Frame   82/598: {'Helmet': 4, 'No Helmet': 5}\n",
      "Frame   83/598: {'Helmet': 4, 'No Helmet': 4}\n",
      "Frame   84/598: {'Helmet': 3, 'No Helmet': 4}\n",
      "Frame   85/598: {'Helmet': 2, 'No Helmet': 3}\n",
      "Frame   86/598: {'Helmet': 2, 'No Helmet': 4}\n",
      "Frame   87/598: {'Helmet': 6, 'No Helmet': 3}\n",
      "Frame   88/598: {'Helmet': 3, 'No Helmet': 4}\n",
      "Frame   89/598: {'Helmet': 4, 'No Helmet': 4}\n",
      "Frame   90/598: {'Helmet': 2, 'No Helmet': 3}\n",
      "Frame   91/598: {'Helmet': 2, 'No Helmet': 4}\n",
      "Frame   92/598: {'Helmet': 2, 'No Helmet': 4}\n",
      "Frame   93/598: {'Helmet': 4, 'No Helmet': 6}\n",
      "Frame   94/598: {'Helmet': 3, 'No Helmet': 4}\n",
      "Frame   95/598: {'Helmet': 5, 'No Helmet': 3}\n",
      "Frame   96/598: {'No Helmet': 5, 'Helmet': 4}\n",
      "Frame   97/598: {'Helmet': 6, 'No Helmet': 3}\n",
      "Frame   98/598: {'No Helmet': 2, 'Helmet': 5}\n",
      "Frame   99/598: {'No Helmet': 2, 'Helmet': 7}\n",
      "Frame  100/598: {'Helmet': 5, 'No Helmet': 3}\n",
      "Frame  101/598: {'Helmet': 7, 'No Helmet': 4}\n",
      "Frame  102/598: {'Helmet': 6, 'No Helmet': 4}\n",
      "Frame  103/598: {'Helmet': 5, 'No Helmet': 4}\n",
      "Frame  104/598: {'Helmet': 4, 'No Helmet': 4}\n",
      "Frame  105/598: {'Helmet': 4, 'No Helmet': 4, 'Person': 1}\n",
      "Frame  106/598: {'Helmet': 6, 'No Helmet': 6, 'Person': 1}\n",
      "Frame  107/598: {'Helmet': 6, 'No Helmet': 5, 'Person': 1}\n",
      "Frame  108/598: {'Helmet': 7, 'No Helmet': 4}\n",
      "Frame  109/598: {'Helmet': 5, 'No Helmet': 6}\n",
      "Frame  110/598: {'Helmet': 2, 'No Helmet': 3}\n",
      "Frame  111/598: {'Helmet': 4, 'No Helmet': 4}\n",
      "Frame  112/598: {'Helmet': 4, 'No Helmet': 4}\n",
      "Frame  113/598: {'Helmet': 5, 'No Helmet': 7}\n",
      "Frame  114/598: {'Helmet': 6, 'No Helmet': 5}\n",
      "Frame  115/598: {'Helmet': 7, 'No Helmet': 4}\n",
      "Frame  116/598: {'Helmet': 7, 'No Helmet': 4}\n",
      "Frame  117/598: {'Helmet': 7, 'No Helmet': 4}\n",
      "Frame  118/598: {'Helmet': 7, 'No Helmet': 3}\n",
      "Frame  119/598: {'Helmet': 4, 'No Helmet': 5}\n",
      "Frame  120/598: {'Helmet': 3, 'No Helmet': 3}\n",
      "Frame  121/598: {'Helmet': 4, 'No Helmet': 3, 'Person': 1}\n",
      "Frame  122/598: {'Helmet': 3, 'No Helmet': 3}\n",
      "Frame  123/598: {'Helmet': 2, 'No Helmet': 3}\n",
      "Frame  124/598: {'Helmet': 2, 'No Helmet': 3}\n",
      "Frame  125/598: {'Helmet': 2, 'No Helmet': 2}\n",
      "Frame  126/598: {'No Helmet': 3, 'Helmet': 1}\n",
      "Frame  127/598: {'Helmet': 2, 'No Helmet': 1}\n",
      "Frame  128/598: {'Helmet': 3, 'No Helmet': 2}\n",
      "Frame  129/598: {'No Helmet': 2, 'Helmet': 3}\n",
      "Frame  130/598: {'No Helmet': 3, 'Helmet': 3}\n",
      "Frame  131/598: {'Helmet': 3, 'No Helmet': 2, 'Person': 1}\n",
      "Frame  132/598: {'No Helmet': 2, 'Person': 2}\n",
      "Frame  133/598: {'No Helmet': 2, 'Helmet': 6}\n",
      "Frame  134/598: {'Helmet': 5, 'No Helmet': 2, 'Person': 1}\n",
      "Frame  135/598: {'Helmet': 2, 'No Helmet': 3, 'Person': 1}\n",
      "Frame  136/598: {'No Helmet': 2, 'Helmet': 3, 'Person': 1}\n",
      "Frame  137/598: {'Helmet': 3, 'No Helmet': 1}\n",
      "Frame  138/598: {'Helmet': 3, 'No Helmet': 2}\n",
      "Frame  139/598: {'Helmet': 2, 'No Helmet': 2}\n",
      "Frame  140/598: {'Helmet': 3, 'No Helmet': 1}\n",
      "Frame  141/598: {'Helmet': 1, 'No Helmet': 2}\n",
      "Frame  142/598: {'Helmet': 2, 'No Helmet': 2}\n",
      "Frame  143/598: {'Helmet': 3, 'No Helmet': 1, 'Person': 1}\n",
      "Frame  144/598: {'Helmet': 4, 'Person': 1, 'No Helmet': 1}\n",
      "Frame  145/598: {'Helmet': 2, 'No Helmet': 1, 'Person': 1}\n",
      "Frame  146/598: {'Helmet': 3, 'No Helmet': 2, 'Person': 1}\n",
      "Frame  150/598: {'Person': 7}\n",
      "Frame  165/598: {'Person': 5, 'Helmet': 2, 'No Helmet': 2}\n",
      "Frame  166/598: {'Person': 5, 'Helmet': 3, 'No Helmet': 1}\n",
      "Frame  168/598: {'Person': 7, 'Helmet': 1, 'No Helmet': 1}\n",
      "Frame  169/598: {'Person': 3, 'Helmet': 1, 'No Helmet': 1}\n",
      "Frame  170/598: {'Helmet': 1, 'Person': 3, 'No Helmet': 1}\n",
      "Frame  188/598: {'Person': 8, 'Motorcycle': 1}\n",
      "Frame  190/598: {'Person': 7, 'Motorcycle': 2}\n",
      "Frame  191/598: {'Person': 8, 'Motorcycle': 1}\n",
      "Frame  197/598: {'Person': 7, 'Helmet': 1, 'Motorcycle': 1}\n",
      "Frame  200/598: {'Person': 6}\n",
      "Frame  205/598: {'Person': 6, 'Motorcycle': 1}\n",
      "Frame  221/598: {'Person': 9, 'Motorcycle': 1}\n",
      "Frame  245/598: {'Helmet': 3, 'No Helmet': 1, 'Person': 1}\n",
      "Frame  246/598: {'Helmet': 3, 'Person': 1, 'No Helmet': 2}\n",
      "Frame  248/598: {'Helmet': 3, 'Person': 1, 'No Helmet': 1}\n",
      "Frame  249/598: {'Helmet': 3, 'No Helmet': 1}\n",
      "Frame  250/598: {'Helmet': 3, 'No Helmet': 2}\n",
      "Frame  251/598: {'Helmet': 4, 'No Helmet': 1}\n",
      "Frame  252/598: {'Helmet': 3, 'No Helmet': 1, 'Person': 1}\n",
      "Frame  253/598: {'Helmet': 2, 'Person': 1, 'No Helmet': 2}\n",
      "Frame  254/598: {'Person': 1, 'Helmet': 4, 'No Helmet': 1}\n",
      "Frame  255/598: {'Helmet': 4, 'Person': 1, 'No Helmet': 1}\n",
      "Frame  256/598: {'Helmet': 3, 'No Helmet': 1}\n",
      "Frame  257/598: {'Helmet': 3, 'No Helmet': 1}\n",
      "Frame  258/598: {'Helmet': 4, 'No Helmet': 2, 'Person': 1}\n",
      "Frame  259/598: {'Helmet': 4, 'No Helmet': 2, 'Person': 1}\n",
      "Frame  260/598: {'No Helmet': 1, 'Person': 1, 'Helmet': 5}\n",
      "Frame  262/598: {'Helmet': 2, 'No Helmet': 1}\n",
      "Frame  263/598: {'Helmet': 3, 'No Helmet': 1}\n",
      "Frame  264/598: {'Helmet': 2, 'No Helmet': 2}\n",
      "Frame  265/598: {'Helmet': 2, 'No Helmet': 2, 'Person': 2}\n",
      "Frame  266/598: {'Helmet': 3, 'No Helmet': 1}\n",
      "Frame  267/598: {'Helmet': 2, 'No Helmet': 1}\n",
      "Frame  269/598: {'Helmet': 3, 'Person': 1, 'No Helmet': 1}\n",
      "Frame  270/598: {'Helmet': 2, 'Person': 1, 'No Helmet': 1}\n",
      "Frame  271/598: {'Helmet': 1, 'Person': 1, 'No Helmet': 2}\n",
      "Frame  272/598: {'Person': 2, 'Helmet': 2, 'No Helmet': 1}\n",
      "Frame  273/598: {'Helmet': 2, 'No Helmet': 2}\n",
      "Frame  274/598: {'Person': 2, 'Helmet': 1, 'No Helmet': 3}\n",
      "Frame  275/598: {'Helmet': 3, 'No Helmet': 1}\n",
      "Frame  276/598: {'Helmet': 3, 'No Helmet': 2}\n",
      "Frame  277/598: {'Helmet': 3, 'No Helmet': 2}\n",
      "Frame  278/598: {'Helmet': 2, 'No Helmet': 2}\n",
      "Frame  279/598: {'Helmet': 3, 'No Helmet': 2}\n",
      "Frame  280/598: {'Helmet': 3, 'No Helmet': 2}\n",
      "Frame  281/598: {'Helmet': 2, 'No Helmet': 3}\n",
      "Frame  282/598: {'Helmet': 2, 'No Helmet': 3}\n",
      "Frame  283/598: {'No Helmet': 1, 'Helmet': 1}\n",
      "Frame  284/598: {'No Helmet': 1}\n",
      "Frame  285/598: {'Helmet': 2, 'No Helmet': 2}\n",
      "Frame  286/598: {'No Helmet': 1, 'Person': 1}\n",
      "Frame  287/598: {'No Helmet': 1, 'Person': 1}\n",
      "Frame  288/598: {'No Helmet': 2, 'Person': 1}\n",
      "Frame  289/598: {'No Helmet': 2, 'Person': 1}\n",
      "Frame  290/598: {'No Helmet': 2}\n",
      "Frame  291/598: {'No Helmet': 2}\n",
      "Frame  292/598: {'No Helmet': 1}\n",
      "Frame  293/598: {'No Helmet': 1}\n",
      "Frame  294/598: {'No Helmet': 1}\n",
      "Frame  295/598: {'No Helmet': 1}\n",
      "Frame  300/598: {'Helmet': 1}\n",
      "Frame  329/598: {'Helmet': 1, 'No Helmet': 1}\n",
      "Frame  345/598: {'Person': 7, 'Motorcycle': 1}\n",
      "Frame  346/598: {'Person': 7, 'Motorcycle': 1}\n",
      "Frame  350/598: {'Person': 7}\n",
      "Frame  362/598: {'Person': 7, 'Motorcycle': 1}\n",
      "Frame  363/598: {'Person': 7, 'Motorcycle': 1}\n",
      "Frame  373/598: {'No Helmet': 1, 'Helmet': 1, 'Person': 2}\n",
      "Frame  374/598: {'Person': 2, 'No Helmet': 1, 'Helmet': 2}\n",
      "Frame  375/598: {'Helmet': 1, 'No Helmet': 1, 'Person': 1}\n",
      "Frame  376/598: {'Person': 2, 'Helmet': 1, 'No Helmet': 1}\n",
      "Frame  377/598: {'Helmet': 1, 'No Helmet': 1, 'Person': 1}\n",
      "Frame  378/598: {'Helmet': 1, 'Person': 1, 'No Helmet': 1}\n",
      "Frame  379/598: {'Helmet': 1, 'No Helmet': 1}\n",
      "Frame  380/598: {'Helmet': 1, 'No Helmet': 1}\n",
      "Frame  381/598: {'Helmet': 1, 'No Helmet': 1}\n",
      "Frame  382/598: {'Helmet': 1, 'No Helmet': 1}\n",
      "Frame  383/598: {'Helmet': 1, 'No Helmet': 2}\n",
      "Frame  384/598: {'Helmet': 1, 'No Helmet': 2}\n",
      "Frame  385/598: {'Helmet': 1, 'No Helmet': 1}\n",
      "Frame  386/598: {'Helmet': 1, 'No Helmet': 1, 'Person': 1}\n",
      "Frame  391/598: {'Helmet': 1, 'No Helmet': 1}\n",
      "Frame  392/598: {'Helmet': 1, 'No Helmet': 1}\n",
      "Frame  393/598: {'Helmet': 2, 'No Helmet': 2}\n",
      "Frame  394/598: {'Helmet': 3, 'No Helmet': 2}\n",
      "Frame  395/598: {'Helmet': 2, 'No Helmet': 1}\n",
      "Frame  396/598: {'Helmet': 1, 'No Helmet': 1}\n",
      "Frame  397/598: {'No Helmet': 1, 'Helmet': 3}\n",
      "Frame  398/598: {'Helmet': 3, 'No Helmet': 2}\n",
      "Frame  399/598: {'Helmet': 2, 'No Helmet': 2}\n",
      "Frame  400/598: {'Helmet': 4, 'No Helmet': 1}\n",
      "Frame  401/598: {'No Helmet': 1, 'Helmet': 2}\n",
      "Frame  402/598: {'No Helmet': 1}\n",
      "Frame  403/598: {'Helmet': 1, 'No Helmet': 1}\n",
      "Frame  404/598: {'No Helmet': 1, 'Helmet': 1}\n",
      "Frame  406/598: {'No Helmet': 1, 'Helmet': 1}\n",
      "Frame  407/598: {'Helmet': 1, 'No Helmet': 1}\n",
      "Frame  408/598: {'No Helmet': 1, 'Helmet': 1}\n",
      "Frame  409/598: {'Helmet': 1, 'No Helmet': 2, 'Person': 1}\n",
      "Frame  410/598: {'Helmet': 2, 'No Helmet': 1, 'Person': 1}\n",
      "Frame  411/598: {'No Helmet': 1, 'Helmet': 2}\n",
      "Frame  412/598: {'No Helmet': 2, 'Helmet': 2, 'Person': 1}\n",
      "Frame  413/598: {'Helmet': 2, 'No Helmet': 1}\n",
      "Frame  414/598: {'Helmet': 2, 'No Helmet': 1, 'Person': 1}\n",
      "Frame  415/598: {'Helmet': 2, 'Person': 1, 'No Helmet': 1}\n",
      "Frame  416/598: {'Helmet': 2, 'No Helmet': 1, 'Person': 1}\n",
      "Frame  417/598: {'Person': 1, 'Helmet': 3, 'No Helmet': 1}\n",
      "Frame  418/598: {'Person': 1, 'Helmet': 2, 'No Helmet': 1}\n",
      "Frame  419/598: {'Helmet': 2, 'Person': 1, 'No Helmet': 1}\n",
      "Frame  420/598: {'Person': 1, 'Helmet': 1, 'No Helmet': 2}\n",
      "Frame  421/598: {'Person': 2, 'No Helmet': 1, 'Helmet': 1}\n",
      "Frame  422/598: {'Person': 2, 'Helmet': 1, 'No Helmet': 1}\n",
      "Frame  423/598: {'Person': 3, 'Helmet': 1, 'No Helmet': 1}\n",
      "Frame  424/598: {'Person': 5, 'Helmet': 1, 'No Helmet': 1}\n",
      "Frame  425/598: {'Person': 5, 'Helmet': 1, 'No Helmet': 1}\n",
      "Frame  427/598: {'Person': 3, 'Helmet': 1, 'No Helmet': 1}\n",
      "Frame  450/598: {'Person': 1}\n",
      "============================================================\n",
      "\n",
      "üìä DETECTION SUMMARY\n",
      "============================================================\n",
      "Total frames processed: 501\n",
      "Frames with detections: 474 (94.6%)\n",
      "\n",
      "Detection counts by class:\n",
      "----------------------------------------\n",
      "  üì¶ Person         :   1158 (avg 2.31/frame)\n",
      "  ‚õëÔ∏è Helmet         :    724 (avg 1.45/frame)\n",
      "  ‚ùå No Helmet      :    520 (avg 1.04/frame)\n",
      "  üèçÔ∏è Motorcycle     :     11 (avg 0.02/frame)\n",
      "----------------------------------------\n",
      "\n",
      "üéØ KEY FINDINGS:\n",
      "   ‚úÖ Motorcycles detected: 11\n",
      "   üö® NO HELMET violations: 520\n",
      "   ‚õëÔ∏è  Helmets detected: 724\n",
      "\n",
      "‚úÖ Detection test completed!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Script test detection ƒë·ªÉ xem model ƒëang detect ƒë∆∞·ª£c g√¨\n",
    "Ch·∫°y cell n√†y ƒë·ªÉ xem k·∫øt qu·∫£ detection tr·ª±c ti·∫øp\n",
    "\"\"\"\n",
    "import cv2\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "# ============ C·∫§U H√åNH ============\n",
    "MODEL_PATH = '../../../app/engine/ckpt/best.pt'  # ho·∫∑c best.onnx\n",
    "VIDEO_PATH = '../../../../videos/no_helmet.mp4'\n",
    "CONF_THRESHOLD = 0.25\n",
    "SHOW_EVERY_N_FRAMES = 1  # Hi·ªÉn th·ªã m·ªói N frame (1 = t·∫•t c·∫£)\n",
    "MAX_FRAMES = 500  # S·ªë frame t·ªëi ƒëa ƒë·ªÉ test (None = to√†n b·ªô video)\n",
    "\n",
    "# ============ CLASS NAMES ============\n",
    "CLASS_NAMES = {\n",
    "    0: 'Car', 1: 'Bus', 2: 'Truck', 3: 'Motorcycle',\n",
    "    4: 'Person', 5: 'Traffic Light', \n",
    "    6: 'Helmet', 7: 'No Helmet', 8: 'License Plate'\n",
    "}\n",
    "\n",
    "VEHICLE_CLASSES = [0, 1, 2, 3]\n",
    "ATTRIBUTE_CLASSES = [6, 7, 8]\n",
    "\n",
    "# ============ LOAD MODEL ============\n",
    "device = 0 if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"üñ•Ô∏è  Device: {'GPU - ' + torch.cuda.get_device_name(0) if device == 0 else 'CPU'}\")\n",
    "\n",
    "model = YOLO(MODEL_PATH, task='detect')\n",
    "print(f\"‚úÖ Model loaded: {MODEL_PATH}\")\n",
    "\n",
    "# ============ OPEN VIDEO ============\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "if not cap.isOpened():\n",
    "    raise Exception(f\"‚ùå Cannot open video: {VIDEO_PATH}\")\n",
    "\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "print(f\"üìπ Video: {VIDEO_PATH}\")\n",
    "print(f\"   Frames: {total_frames}, FPS: {fps}, Size: {width}x{height}\")\n",
    "\n",
    "# ============ DETECTION STATS ============\n",
    "detection_counts = defaultdict(int)\n",
    "frames_with_detections = 0\n",
    "\n",
    "# ============ PROCESS VIDEO ============\n",
    "print(\"\\nüîç Starting detection...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "frame_count = 0\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    frame_count += 1\n",
    "    if MAX_FRAMES and frame_count > MAX_FRAMES:\n",
    "        break\n",
    "    \n",
    "    # Run detection\n",
    "    results = model(frame, device=device, verbose=False, conf=CONF_THRESHOLD)\n",
    "    \n",
    "    if results and results[0].boxes and len(results[0].boxes) > 0:\n",
    "        boxes = results[0].boxes\n",
    "        frames_with_detections += 1\n",
    "        \n",
    "        # Count detections\n",
    "        frame_detections = defaultdict(int)\n",
    "        for box in boxes:\n",
    "            cls_id = int(box.cls[0])\n",
    "            cls_name = CLASS_NAMES.get(cls_id, f\"Unknown({cls_id})\")\n",
    "            detection_counts[cls_name] += 1\n",
    "            frame_detections[cls_name] += 1\n",
    "        \n",
    "        # Print frame info (m·ªói 50 frame ho·∫∑c khi c√≥ detection ƒë·∫∑c bi·ªát)\n",
    "        if frame_count % 50 == 0 or 'No Helmet' in frame_detections or 'Motorcycle' in frame_detections:\n",
    "            print(f\"Frame {frame_count:4d}/{total_frames}: {dict(frame_detections)}\")\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# ============ SUMMARY ============\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nüìä DETECTION SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total frames processed: {frame_count}\")\n",
    "print(f\"Frames with detections: {frames_with_detections} ({frames_with_detections/frame_count*100:.1f}%)\")\n",
    "print(f\"\\nDetection counts by class:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for cls_name, count in sorted(detection_counts.items(), key=lambda x: -x[1]):\n",
    "    avg_per_frame = count / frame_count\n",
    "    icon = \"üèçÔ∏è\" if cls_name == \"Motorcycle\" else \"üöó\" if cls_name == \"Car\" else \"‚õëÔ∏è\" if cls_name == \"Helmet\" else \"‚ùå\" if cls_name == \"No Helmet\" else \"üìã\" if cls_name == \"License Plate\" else \"üì¶\"\n",
    "    print(f\"  {icon} {cls_name:15s}: {count:6d} (avg {avg_per_frame:.2f}/frame)\")\n",
    "\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# ============ HIGHLIGHT KEY FINDINGS ============\n",
    "print(\"\\nüéØ KEY FINDINGS:\")\n",
    "if 'Motorcycle' in detection_counts:\n",
    "    print(f\"   ‚úÖ Motorcycles detected: {detection_counts['Motorcycle']}\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è  No motorcycles detected!\")\n",
    "\n",
    "if 'No Helmet' in detection_counts:\n",
    "    print(f\"   üö® NO HELMET violations: {detection_counts['No Helmet']}\")\n",
    "else:\n",
    "    print(f\"   ‚ÑπÔ∏è  No 'No Helmet' detections\")\n",
    "\n",
    "if 'Helmet' in detection_counts:\n",
    "    print(f\"   ‚õëÔ∏è  Helmets detected: {detection_counts['Helmet']}\")\n",
    "\n",
    "if 'License Plate' in detection_counts:\n",
    "    print(f\"   üìã License plates detected: {detection_counts['License Plate']}\")\n",
    "\n",
    "print(\"\\n‚úÖ Detection test completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6601e006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 507: Car: 6\n",
      "\n",
      "‚èπÔ∏è Stopped by user\n",
      "\n",
      "‚úÖ Processed 507 frames\n",
      "üé¨ Visualization completed!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "üé¨ REALTIME VISUALIZATION\n",
    "Hi·ªÉn th·ªã video v·ªõi bounding boxes v√† th√¥ng tin detection\n",
    "\"\"\"\n",
    "import cv2\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from IPython.display import display, clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# ============ C·∫§U H√åNH ============\n",
    "MODEL_PATH = '../../../app/engine/ckpt/best.pt'\n",
    "VIDEO_PATH = '../../../../videos/dau_vung_cam.mp4'\n",
    "CONF_THRESHOLD = 0.25\n",
    "DISPLAY_SIZE = (960, 540)  # Resize ƒë·ªÉ hi·ªÉn th·ªã nhanh h∆°n\n",
    "\n",
    "# ============ CLASS CONFIG ============\n",
    "CLASS_NAMES = {\n",
    "    0: 'Car', 1: 'Bus', 2: 'Truck', 3: 'Motorcycle',\n",
    "    4: 'Person', 5: 'Traffic Light', \n",
    "    6: 'Helmet', 7: 'No Helmet', 8: 'License Plate'\n",
    "}\n",
    "\n",
    "# M√†u s·∫Øc cho t·ª´ng class (BGR)\n",
    "CLASS_COLORS = {\n",
    "    0: (0, 255, 0),      # Car - Green\n",
    "    1: (255, 165, 0),    # Bus - Orange\n",
    "    2: (0, 0, 255),      # Truck - Red\n",
    "    3: (255, 255, 0),    # Motorcycle - Cyan\n",
    "    4: (128, 0, 128),    # Person - Purple\n",
    "    5: (0, 255, 255),    # Traffic Light - Yellow\n",
    "    6: (0, 255, 0),      # Helmet - Green\n",
    "    7: (0, 0, 255),      # No Helmet - RED (quan tr·ªçng!)\n",
    "    8: (255, 0, 255),    # License Plate - Magenta\n",
    "}\n",
    "\n",
    "# ============ LOAD MODEL ============\n",
    "device = 0 if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"üñ•Ô∏è  Device: {'GPU - ' + torch.cuda.get_device_name(0) if device == 0 else 'CPU'}\")\n",
    "\n",
    "model = YOLO(MODEL_PATH, task='detect')\n",
    "print(f\"‚úÖ Model loaded: {MODEL_PATH}\")\n",
    "\n",
    "# ============ OPEN VIDEO ============\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "if not cap.isOpened():\n",
    "    raise Exception(f\"‚ùå Cannot open video: {VIDEO_PATH}\")\n",
    "\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "print(f\"üìπ Video: {total_frames} frames @ {fps} FPS\")\n",
    "\n",
    "# ============ VISUALIZATION FUNCTION ============\n",
    "def draw_detections(frame, boxes, class_names, class_colors, conf_threshold=0.25):\n",
    "    \"\"\"V·∫Ω bounding boxes v√† labels l√™n frame\"\"\"\n",
    "    detection_info = defaultdict(int)\n",
    "    \n",
    "    for box in boxes:\n",
    "        cls_id = int(box.cls[0])\n",
    "        conf = float(box.conf[0])\n",
    "        \n",
    "        if conf < conf_threshold:\n",
    "            continue\n",
    "            \n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())\n",
    "        cls_name = class_names.get(cls_id, f\"Unknown({cls_id})\")\n",
    "        color = class_colors.get(cls_id, (128, 128, 128))\n",
    "        \n",
    "        detection_info[cls_name] += 1\n",
    "        \n",
    "        # V·∫Ω box - d√†y h∆°n cho No Helmet\n",
    "        thickness = 3 if cls_id == 7 else 2\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), color, thickness)\n",
    "        \n",
    "        # Label background\n",
    "        label = f\"{cls_name} {conf:.2f}\"\n",
    "        (label_w, label_h), baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)\n",
    "        cv2.rectangle(frame, (x1, y1 - label_h - 10), (x1 + label_w, y1), color, -1)\n",
    "        cv2.putText(frame, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "        \n",
    "        # Th√™m icon cho No Helmet\n",
    "        if cls_id == 7:  # No Helmet\n",
    "            cv2.putText(frame, \"‚ö†Ô∏è VIOLATION!\", (x1, y2 + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "    \n",
    "    return frame, detection_info\n",
    "\n",
    "def draw_stats_overlay(frame, detection_info, frame_num, total_frames):\n",
    "    \"\"\"V·∫Ω overlay th·ªëng k√™ l√™n g√≥c m√†n h√¨nh\"\"\"\n",
    "    overlay = frame.copy()\n",
    "    h, w = frame.shape[:2]\n",
    "    \n",
    "    # Background panel\n",
    "    cv2.rectangle(overlay, (10, 10), (280, 150), (0, 0, 0), -1)\n",
    "    cv2.addWeighted(overlay, 0.7, frame, 0.3, 0, frame)\n",
    "    \n",
    "    # Title\n",
    "    cv2.putText(frame, f\"Frame: {frame_num}/{total_frames}\", (20, 35), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "    \n",
    "    # Detection counts\n",
    "    y_offset = 60\n",
    "    for cls_name, count in sorted(detection_info.items()):\n",
    "        color = (0, 255, 0) if cls_name not in ['No Helmet'] else (0, 0, 255)\n",
    "        cv2.putText(frame, f\"{cls_name}: {count}\", (20, y_offset), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "        y_offset += 20\n",
    "    \n",
    "    return frame\n",
    "\n",
    "# ============ REALTIME DISPLAY ============\n",
    "print(\"\\nüé¨ Starting realtime visualization...\")\n",
    "print(\"   Displaying frames in notebook (every 3rd frame for speed)\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(14, 8))\n",
    "plt.ion()  # Interactive mode\n",
    "\n",
    "frame_count = 0\n",
    "skip_frames = 2  # Hi·ªÉn th·ªã m·ªói 3 frame ƒë·ªÉ m∆∞·ª£t h∆°n trong notebook\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame_count += 1\n",
    "        \n",
    "        # Skip frames ƒë·ªÉ tƒÉng t·ªëc\n",
    "        if frame_count % (skip_frames + 1) != 0:\n",
    "            continue\n",
    "        \n",
    "        # Run detection\n",
    "        results = model(frame, device=device, verbose=False, conf=CONF_THRESHOLD)\n",
    "        \n",
    "        # Draw detections\n",
    "        detection_info = {}\n",
    "        if results and results[0].boxes and len(results[0].boxes) > 0:\n",
    "            frame, detection_info = draw_detections(\n",
    "                frame, results[0].boxes, CLASS_NAMES, CLASS_COLORS, CONF_THRESHOLD\n",
    "            )\n",
    "        \n",
    "        # Draw stats overlay\n",
    "        frame = draw_stats_overlay(frame, detection_info, frame_count, total_frames)\n",
    "        \n",
    "        # Resize for display\n",
    "        frame_resized = cv2.resize(frame, DISPLAY_SIZE)\n",
    "        \n",
    "        # Convert BGR to RGB for matplotlib\n",
    "        frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Display in notebook\n",
    "        clear_output(wait=True)\n",
    "        ax.clear()\n",
    "        ax.imshow(frame_rgb)\n",
    "        ax.axis('off')\n",
    "        ax.set_title(f\"üé¨ Realtime Detection - Frame {frame_count}/{total_frames}\", fontsize=14)\n",
    "        \n",
    "        # Print current detections\n",
    "        if detection_info:\n",
    "            det_str = \", \".join([f\"{k}: {v}\" for k, v in detection_info.items()])\n",
    "            print(f\"Frame {frame_count}: {det_str}\")\n",
    "            if 'No Helmet' in detection_info:\n",
    "                print(f\"   üö® VIOLATION!!!!\")\n",
    "        \n",
    "        display(fig)\n",
    "        \n",
    "        # D·ª´ng s·ªõm n·∫øu c·∫ßn (nh·∫•n interrupt kernel)\n",
    "        if frame_count > 1000:  # Gi·ªõi h·∫°n 300 frames ƒë·ªÉ test\n",
    "            print(\"\\n‚èπÔ∏è Stopped at 300 frames for demo\")\n",
    "            break\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n‚èπÔ∏è Stopped by user\")\n",
    "finally:\n",
    "    cap.release()\n",
    "    plt.close(fig)\n",
    "    print(f\"\\n‚úÖ Processed {frame_count} frames\")\n",
    "    print(\"üé¨ Visualization completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "be-fastapi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
