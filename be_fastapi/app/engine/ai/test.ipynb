{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc79dec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from ultralytics import YOLO\n",
    "from shapely.geometry import Point, Polygon\n",
    "from collections import defaultdict\n",
    "from sqlalchemy.orm import Session\n",
    "from be_fastapi.app.database.session import SessionLocal\n",
    "from be_fastapi.app.models.zone import Zone \n",
    "\n",
    "class VideoProcessor:\n",
    "    def __init__(self, model_path='be_fastapi\\\\app\\\\engine\\\\ckpt\\\\best.onnx', source_id=None):\n",
    "        \"\"\"\n",
    "        model_path: checkpoint (.pt or .onnx)\n",
    "        source_id: source ID\n",
    "        \"\"\"\n",
    "        self.source_id = source_id\n",
    "        if model_path.endswith('.onnx'):\n",
    "            self.device = 'cpu'\n",
    "            print(f\"[Source {self.source_id}] Running ONNX mode on CPU\")\n",
    "        else:\n",
    "            self.device = 0 if torch.cuda.is_available() else 'cpu'\n",
    "            print(f\"[Source {self.source_id}] Using device: {torch.cuda.get_device_name(0) if self.device == 0 else 'CPU'}\")\n",
    "\n",
    "        self.model = YOLO(model_path, task='detect')\n",
    "\n",
    "        self.CLASS_NAMES = {\n",
    "            0: 'Car', 1: 'Bus', 2: 'Truck', 3: 'Motorcycle',\n",
    "            4: 'Person', 5: 'Traffic Light', \n",
    "            6: 'Helmet', 7: 'No Helmet', 8: 'License Plate'\n",
    "        }\n",
    "        \n",
    "        self.VEHICLE_CLASSES = [0, 1, 2, 3] \n",
    "        self.ATTRIBUTE_CLASSES = [6, 7, 8]\n",
    "        \n",
    "        # load zones from DB\n",
    "        self.zones = {} \n",
    "        if self.source_id:\n",
    "            self.load_zones_from_db(self.source_id)\n",
    "        else:\n",
    "            print(\"No source_id provided, cannot load zones.\")\n",
    "        \n",
    "        # Temporary memory\n",
    "        self.track_history = defaultdict(lambda: [])\n",
    "        self.zone_entry_times = defaultdict(lambda: {})\n",
    "\n",
    "    def load_zones_from_db(self, source_id):\n",
    "        \"\"\"\n",
    "        Load zones from the database for the given source_id.\n",
    "        \"\"\"\n",
    "        db: Session = SessionLocal()\n",
    "        try:\n",
    "            db_zones = db.query(Zone).filter(Zone.source_id == source_id).all()\n",
    "            \n",
    "            self.zones = {}\n",
    "            for z in db_zones:\n",
    "                try:\n",
    "                    points = z.coordinates\n",
    "                    if isinstance(points, str):\n",
    "                        points = json.loads(points) #convert to list if stored as string\n",
    "                    if points and isinstance(points, list) and len(points) >= 3:\n",
    "                        poly = Polygon(points)\n",
    "                        self.zones[z.name] = poly\n",
    "                    else:\n",
    "                        print(f\"Zone '{z.name}' has invalid coordinates.\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error parsing zone '{z.name}': {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error connecting to Database when loading zones: {e}\")\n",
    "        finally:\n",
    "            db.close()\n",
    "\n",
    "    def calculate_iou(self, box1, box2):\n",
    "        \"\"\"\n",
    "            Calculate Intersection over Union (IoU) of two bounding boxes.\n",
    "            box1, box2: [x_min, y_min, x_max, y_max]\n",
    "        \"\"\"\n",
    "        x1 = max(box1[0], box2[0])\n",
    "        y1 = max(box1[1], box2[1])\n",
    "        x2 = min(box1[2], box2[2])\n",
    "        y2 = min(box1[3], box2[3])\n",
    "        \n",
    "        intersection = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "        area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "        area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "        \n",
    "        if area1 + area2 - intersection == 0: return 0\n",
    "        return intersection / (area1 + area2 - intersection)\n",
    "\n",
    "    def estimate_speed(self, track_id, current_center):\n",
    "        \"\"\"\n",
    "            Estimate speed in km/h based on pixel movement.\n",
    "            track_id: ID of the tracked object\n",
    "            sclae_factor: conversion factor from pixels to meters, in this case 0.05 m/pixel\n",
    "        \"\"\"\n",
    "        scale_factor = 0.05\n",
    "        if track_id not in self.track_history or len(self.track_history[track_id]) < 2:\n",
    "            return 0.0\n",
    "        prev_center = self.track_history[track_id][-1]\n",
    "        pixel_dist = np.sqrt((current_center[0] - prev_center[0])**2 + (current_center[1] - prev_center[1])**2)\n",
    "        speed_mps = pixel_dist * scale_factor * 30 \n",
    "        return round(speed_mps * 3.6, 1)\n",
    "\n",
    "    def process_video(self, video_source=0):\n",
    "        cap = cv2.VideoCapture(video_source)\n",
    "        \n",
    "        while cap.isOpened():\n",
    "            success, frame = cap.read()\n",
    "            if not success: break\n",
    "\n",
    "            # Run detection and tracking\n",
    "            results = self.model.track(\n",
    "                frame, \n",
    "                persist=True, \n",
    "                tracker=\"bytetrack.yaml\", \n",
    "                device=self.device,\n",
    "                verbose=False,\n",
    "                conf=0.25\n",
    "            )\n",
    "            \n",
    "            # If no detections, just show original frame\n",
    "            if not results or not results[0].boxes:\n",
    "                cv2.imshow(f\"Cam {self.source_id}\", frame)\n",
    "                if cv2.waitKey(1) & 0xFF == ord(\"q\"): break\n",
    "                continue\n",
    "\n",
    "            # Process results\n",
    "            boxes = results[0].boxes\n",
    "            current_timestamp = datetime.utcnow().isoformat() + \"Z\" # ISO 8601 format\n",
    "            \n",
    "            # Classify boxes into vehicles and attributes\n",
    "            vehicles = []\n",
    "            attributes = []\n",
    "            for box in boxes:\n",
    "                cls_id = int(box.cls[0])\n",
    "                if cls_id in self.VEHICLE_CLASSES:\n",
    "                    vehicles.append(box)\n",
    "                elif cls_id in self.ATTRIBUTE_CLASSES:\n",
    "                    attributes.append(box)\n",
    "\n",
    "            # Process each vehicle\n",
    "            dsl_objects = []\n",
    "            for veh in vehicles:\n",
    "                if veh.id is None: continue \n",
    "                \n",
    "                track_id = int(veh.id[0])\n",
    "                cls_id = int(veh.cls[0])\n",
    "                x1, y1, x2, y2 = veh.xyxy[0].tolist()\n",
    "                center_point = Point((x1 + x2) / 2, (y1 + y2) / 2)\n",
    "                center_tuple = ((x1 + x2) / 2, (y1 + y2) / 2)\n",
    "\n",
    "                self.track_history[track_id].append(center_tuple)\n",
    "                if len(self.track_history[track_id]) > 30:\n",
    "                    self.track_history[track_id].pop(0)\n",
    "\n",
    "                # Gh√©p thu·ªôc t√≠nh\n",
    "                has_helmet = None\n",
    "                license_text = \"Unknown\"\n",
    "                veh_box = [x1, y1, x2, y2]\n",
    "                \n",
    "                for attr in attributes:\n",
    "                    attr_box = attr.xyxy[0].tolist()\n",
    "                    attr_id = int(attr.cls[0])\n",
    "                    if self.calculate_iou(veh_box, attr_box) > 0.01:\n",
    "                        if attr_id == 6: has_helmet = True\n",
    "                        elif attr_id == 7: has_helmet = False\n",
    "                        elif attr_id == 8: license_text = \"DETECTED_PLATE\"\n",
    "\n",
    "                current_zone_name = None\n",
    "                zone_durations = {}\n",
    "                for z_name, z_poly in self.zones.items():\n",
    "                    if z_poly.contains(center_point):\n",
    "                        current_zone_name = z_name \n",
    "                        \n",
    "                        if track_id not in self.zone_entry_times: self.zone_entry_times[track_id] = {}\n",
    "                        if z_name not in self.zone_entry_times[track_id]: self.zone_entry_times[track_id][z_name] = datetime.now()\n",
    "                        \n",
    "                        duration = (datetime.now() - self.zone_entry_times[track_id][z_name]).total_seconds()\n",
    "                        zone_durations[z_name] = round(duration, 1)\n",
    "                    else:\n",
    "                        if track_id in self.zone_entry_times and z_name in self.zone_entry_times[track_id]:\n",
    "                            del self.zone_entry_times[track_id][z_name]\n",
    "\n",
    "                obj_data = {\n",
    "                    \"track_id\": track_id,\n",
    "                    \"class_name\": self.CLASS_NAMES[cls_id],\n",
    "                    \"class_id\": cls_id,\n",
    "                    \"bbox\": [int(x1), int(y1), int(x2), int(y2)],\n",
    "                    \"confidence\": float(veh.conf[0]),\n",
    "                    \"speed_kmh\": self.estimate_speed(track_id, center_tuple),\n",
    "                    \"direction_angle\": 0.0,\n",
    "                    \"current_zone\": current_zone_name,\n",
    "                    \"zone_duration_seconds\": zone_durations,\n",
    "                    \"attributes\": {\n",
    "                        \"has_helmet\": has_helmet,\n",
    "                        \"license_plate_text\": license_text\n",
    "                    }\n",
    "                }\n",
    "                dsl_objects.append(obj_data)\n",
    "\n",
    "            final_json = {\n",
    "                \"source_id\": str(self.source_id), # G·ª≠i ID camera ƒëi k√®m\n",
    "                \"frame_timestamp\": current_timestamp,\n",
    "                \"objects\": dsl_objects\n",
    "            }\n",
    "            \n",
    "\n",
    "            annotated_frame = results[0].plot()\n",
    "            # V·∫Ω v√πng l√™n h√¨nh ƒë·ªÉ debug\n",
    "            for z_name, z_poly in self.zones.items():\n",
    "                pts = np.array(z_poly.exterior.coords, np.int32)\n",
    "                pts = pts.reshape((-1, 1, 2))\n",
    "                cv2.polylines(annotated_frame, [pts], True, (0, 255, 255), 2)\n",
    "                cv2.putText(annotated_frame, z_name, (pts[0][0][0], pts[0][0][1]), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 255), 2)\n",
    "\n",
    "            cv2.imshow(f\"Cam {self.source_id}\", annotated_frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\"\n",
    "    H√†m main ƒë·ªÉ test AI Engine ƒë·ªôc l·∫≠p.\n",
    "    Ch·∫°y file n√†y tr·ª±c ti·∫øp ƒë·ªÉ debug v√† ki·ªÉm tra xem model c√≥ ho·∫°t ƒë·ªông ƒë√∫ng kh√¥ng.\n",
    "    \"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"üöÄ Starting AI Engine Test Mode\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # --- C·∫•u h√¨nh ---\n",
    "    TEST_SOURCE_ID = 1  # ID c·ªßa camera trong Database\n",
    "    MODEL_PATH = 'be_fastapi\\\\app\\\\engine\\\\ckpt\\\\best.onnx'  # ƒê∆∞·ªùng d·∫´n model\n",
    "    VIDEO_SOURCE = 'test_video.mp4'  # C√≥ th·ªÉ l√† file video ho·∫∑c 0 cho webcam\n",
    "    \n",
    "    # --- Kh·ªüi t·∫°o Processor ---\n",
    "    try:\n",
    "        processor = VideoProcessor(\n",
    "            model_path=MODEL_PATH,\n",
    "            source_id=TEST_SOURCE_ID\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ Model loaded successfully: {MODEL_PATH}\")\n",
    "        print(f\"‚úÖ Loaded {len(processor.zones)} zones from database for Source ID {TEST_SOURCE_ID}\")\n",
    "        \n",
    "        if len(processor.zones) == 0:\n",
    "            print(\"‚ö†Ô∏è  WARNING: No zones found! Make sure database has zones for this source_id.\")\n",
    "        \n",
    "        print(\"\\nüìπ Starting video processing...\")\n",
    "        print(\"   Press 'q' to quit\\n\")\n",
    "        \n",
    "        # --- Ch·∫°y x·ª≠ l√Ω video ---\n",
    "        processor.process_video(video_source=VIDEO_SOURCE)\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå ERROR: Model file not found at: {MODEL_PATH}\")\n",
    "        print(\"   Please check the path and make sure the model file exists.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ERROR: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    finally:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"üõë AI Engine stopped\")\n",
    "        print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e167ab36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Loading model...\n",
      "üîÑ Exporting to ONNX (without simplify)...\n",
      "Ultralytics YOLOv8.1.34 üöÄ Python-3.11.14 torch-2.6.0+cpu CPU (13th Gen Intel Core(TM) i9-13900HX)\n",
      "YOLOv10s summary (fused): 293 layers, 8041926 parameters, 0 gradients, 24.5 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'D:\\projects\\Vehicle_Fault_Dectection\\be_fastapi\\app\\engine\\ckpt\\best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 300, 6) (93.3 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.20.0 opset 12...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 0.7s, saved as 'D:\\projects\\Vehicle_Fault_Dectection\\be_fastapi\\app\\engine\\ckpt\\best.onnx' (27.6 MB)\n",
      "\n",
      "Export complete (2.4s)\n",
      "Results saved to \u001b[1mD:\\projects\\Vehicle_Fault_Dectection\\be_fastapi\\app\\engine\\ckpt\u001b[0m\n",
      "Predict:         yolo predict task=detect model=D:\\projects\\Vehicle_Fault_Dectection\\be_fastapi\\app\\engine\\ckpt\\best.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=D:\\projects\\Vehicle_Fault_Dectection\\be_fastapi\\app\\engine\\ckpt\\best.onnx imgsz=640 data=/home/ltnhanh/vfimamba_explore/data_test/Final_Traffic_Dataset/data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "‚úÖ Export th√†nh c√¥ng!\n",
      "üìÅ File: D:\\projects\\Vehicle_Fault_Dectection\\be_fastapi\\app\\engine\\ckpt\\best.onnx\n",
      "\n",
      "üß™ Testing ONNX model...\n",
      "WARNING ‚ö†Ô∏è Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify','pose' or 'obb'.\n",
      "‚úÖ ONNX ho·∫°t ƒë·ªông OK!\n"
     ]
    }
   ],
   "source": [
    "# VSCode.Cell\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import gc\n",
    "\n",
    "# T·∫Øt weights_only security\n",
    "_original_load = torch.load\n",
    "def patched_load(*args, **kwargs):\n",
    "    kwargs['weights_only'] = False\n",
    "    return _original_load(*args, **kwargs)\n",
    "torch.load = patched_load\n",
    "\n",
    "try:\n",
    "    print(\"üîÑ Loading model...\")\n",
    "    model = YOLO('D:\\\\projects\\\\Vehicle_Fault_Dectection\\\\be_fastapi\\\\app\\\\engine\\\\ckpt\\\\best.pt')\n",
    "    \n",
    "    print(\"üîÑ Exporting to ONNX (without simplify)...\")\n",
    "    onnx_path = model.export(\n",
    "        format='onnx',\n",
    "        imgsz=640,\n",
    "        dynamic=True,\n",
    "        simplify=False,  # ‚ö†Ô∏è T·∫Øt simplify ƒë·ªÉ tr√°nh crash\n",
    "        opset=12,\n",
    "        half=False\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Export th√†nh c√¥ng!\")\n",
    "    print(f\"üìÅ File: {onnx_path}\")\n",
    "    \n",
    "    # Clear memory\n",
    "    del model\n",
    "    gc.collect()\n",
    "    \n",
    "    # Test ONNX\n",
    "    print(\"\\nüß™ Testing ONNX model...\")\n",
    "    onnx_model = YOLO(onnx_path)\n",
    "    print(\"‚úÖ ONNX ho·∫°t ƒë·ªông OK!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå L·ªói: {e}\")\n",
    "finally:\n",
    "    torch.load = _original_load"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "be-fastapi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
